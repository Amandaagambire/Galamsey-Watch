{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM22NzDeVRtkR+TlDigF3nx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amandaagambire/Galamsey-Watch/blob/main/G_watch_copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install Earth Engine**"
      ],
      "metadata": {
        "id": "Yg5BtzUQU6Qy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qikoNBhvUQDO"
      },
      "outputs": [],
      "source": [
        "!pip install earthengine-api geemap folium rasterio\n",
        "!pip install segmentation-models-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Authenticate & Initialize earth engine**"
      ],
      "metadata": {
        "id": "5wWtyLKPU9C9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import ee\n",
        "import geemap\n",
        "import folium\n",
        "import rasterio\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from skimage.color import rgb2gray\n",
        "from skimage import exposure\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "from skimage.measure import label, regionprops\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "\n",
        "# Mount Google Drive\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "#Authenticae then initialise google Earth Engine\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project = 'ee-agamaamanda')\n",
        "print(\"Earth Engine Initialized\")\n"
      ],
      "metadata": {
        "id": "Z1WkSYedU3kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA ACQUISITION: Fetching Sentinel -2 Images**"
      ],
      "metadata": {
        "id": "9LfiF6sVVCas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# set coordinates Region of interest  -> (Ghana)\n",
        "region = ee.Geometry.Rectangle([-3.3, 4.5, 1.3, 11.2])  # (long, lat)\n",
        "\n",
        "\n",
        "def preprocess_image(image):\n",
        "      return image.select(['B4', 'B3', 'B2']).divide(10000) # Blue, Green, Red, NIR\n",
        "\n",
        "def fetch_sentinel_image():\n",
        "  # Get Sentinel-2 image collection\n",
        "  sentinel = ee.ImageCollection(\"COPERNICUS/S2\") \\\n",
        "              .filterBounds(region) \\\n",
        "              .filterDate('2024-01-01', '2024-12-31') \\\n",
        "              .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\\\n",
        "              .map(preprocess_image) \\\n",
        "              .median() \\\n",
        "              # .clip(region) # Get just the region\n",
        "  print(\"Sentinel-2 image preprocessed successfully!\")\n",
        "  return sentinel\n",
        "\n",
        "  # Display metadata\n",
        "  print(sentinel.getInfo())\n"
      ],
      "metadata": {
        "id": "R8ThROxJVC6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fetching Landsat-8 Images (UNNECESSARY?)**\n",
        "\n"
      ],
      "metadata": {
        "id": "23YF_mloVEva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get Landsat-8 image collection\n",
        "landsat = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\") \\\n",
        "            .filterBounds(region) \\\n",
        "            .filterDate('2022-01-01', '2024-12-31') \\\n",
        "            .median()\n",
        "\n",
        "# Select RGB bands\n",
        "landsat_rgb = landsat.select(['SR_B4', 'SR_B3', 'SR_B2'])\n",
        "\n",
        "# Print metadata\n",
        "print(landsat.getInfo())\n"
      ],
      "metadata": {
        "id": "Pl8lIAHqVHE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Vizulaize the Extracted images**"
      ],
      "metadata": {
        "id": "cKZ-hSh0VI1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Map = geemap.Map(center = [5.2, -2.1], zoom=10)\n",
        "\n",
        "Map.addLayer(sentinel, {'min': 0, 'max': 3000}, \"Sentinel-2 RGB\")\n",
        "Map.addLayer(landsat_rgb, {'min': 0, 'max': 3000}, \"Landsat-8\")\n",
        "\n",
        "#Lets see it\n",
        "Map"
      ],
      "metadata": {
        "id": "CTCooMdzVMZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Export images to Google Drive**"
      ],
      "metadata": {
        "id": "LLsceG94VODe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def export_image_to_drive(image, description='Sentinel-2_Mining_Area', folder = 'GEE_Exports'):\n",
        "  export_task = ee.batch.Export.image.toDrive(\n",
        "      image=image,\n",
        "      description=description,\n",
        "      scale=30,\n",
        "      region=region,\n",
        "      fileFormat='GeoTIFF',\n",
        "      folder= folder  # This is where the file will be saved in Drive\n",
        "  )\n",
        "  # Start the export task\n",
        "  export_task.start()\n",
        "  print(\"Export started! Check Google Drive â†’ GEE_Exports folder in 5-10 minutes.\")\n",
        "\n",
        "\n",
        "\n",
        "task_list = ee.batch.Task.list()\n",
        "for task in task_list:\n",
        "    print(task.status())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YThDboNUVQMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Moves a file from Google Drive to Colab**"
      ],
      "metadata": {
        "id": "0-C1LILFVSJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def move_file_from_drive_to_colab(source_path_on_drive, destination_path_on_colab):\n",
        "    \"\"\"Moves a file from Google Drive to Colab.\"\"\"\n",
        "    if IN_COLAB:\n",
        "        source_path = f\"/content/drive/My Drive/{source_path_on_drive}\"\n",
        "        try:\n",
        "            shutil.copy(source_path, destination_path_on_colab)\n",
        "            print(f\"File moved to Colab: {destination_path_on_colab}\")\n",
        "            return True\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: Source file not found at {source_path}\")\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            print(f\"Error moving file: {e}\")\n",
        "            return False\n",
        "    else:\n",
        "        print(\"Not running in Colab, skipping file move.\")\n",
        "        return False\n",
        "\n",
        "local_image_path = '/content/Sentinel2_Mining_Area.tif' # Assuming you have downloaded or moved the image\n"
      ],
      "metadata": {
        "id": "-EYbtxZsVUeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Download & Label for training**"
      ],
      "metadata": {
        "id": "hmXkus4uVXQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check if file exists in Google Colab\n",
        "print(os.listdir('/content/'))\n"
      ],
      "metadata": {
        "id": "Dxb0S_kGVZXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  with rasterio.open(local_image_path) as src:\n",
        "    image_array = src.read()\n",
        "    image_metadata = src.profile\n",
        "    red_band = image_array[0].astype(np.float32)\n",
        "    green_band = image_array[1].astype(np.float32)\n",
        "    blue_band = image_array[2].astype(np.float32)\n",
        "    # nir_band = image_array[3]\n",
        "except Exception as e:\n",
        "    print(f\"Error opening the image: {e}\")\n",
        "\n",
        "print(image_array.shape)\n",
        "  # Print metadta\n",
        "print(image_metadata)\n"
      ],
      "metadata": {
        "id": "m_mUwQxkVcyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **U-Net Model Definition**"
      ],
      "metadata": {
        "id": "q-ocX5puVfh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from logging import log\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNet, self).__init__()\n",
        "        self.inc = DoubleConv(in_channels, 64)\n",
        "        self.outc = nn.Conv2d(64, out_channels, kernel_size=1) # Simplified output\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        logits = self.outc(x1)\n",
        "        return logits\n",
        "\n",
        "# Load a pre-trained model (replace with the actual path to your trained model)\n",
        "n_channels = 3\n",
        "n_classes = 1\n",
        "model = UNet(n_channels, n_classes)\n",
        "try:\n",
        "    model.load_state_dict(torch.load('/content/drive/My Drive/galamsey_unet_simplified.pth', map_location=torch.device('cpu'))) # Load on CPU for simplicity\n",
        "    model.eval()\n",
        "    print(\"Pre-trained U-Net model loaded successfully!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Pre-trained U-Net model not found. Please train and save your model.\")\n",
        "    model = None\n",
        "\n",
        "# Define image transformation for prediction\n",
        "predict_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "wa8JUQGdVgE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prediction Function**"
      ],
      "metadata": {
        "id": "c6FPZXoqVi2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_mining_site(image_array, model, transform, device='cpu'):\n",
        "    \"\"\"\n",
        "    Performs prediction on an image using the U-Net model.\n",
        "\n",
        "    Args:\n",
        "        image_array (numpy.ndarray): The input image array (e.g., RGB).\n",
        "        model (torch.nn.Module): The trained U-Net model.\n",
        "        transform (torch.transforms): The image transformation pipeline.\n",
        "        device (str): 'cpu' or 'cuda'.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray or None: The binary prediction mask (1 for mining, 0 otherwise), or None if model is not loaded.\n",
        "    \"\"\"\n",
        "    if model is None or image_array is None:\n",
        "        print(\"Error: Model not loaded or image not available for prediction.\")\n",
        "        return None\n",
        "\n",
        "    # Assuming image_array is (bands, height, width), we need (height, width, bands) for PIL\n",
        "    rgb_image = np.transpose(image_array[:3, :, :], (1, 2, 0))\n",
        "    pil_image = Image.fromarray(rgb_image).convert('RGB')\n",
        "    input_tensor = transform(pil_image).unsqueeze(0).to(device) # Add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        prediction = torch.sigmoid(output).squeeze().cpu().numpy() > 0.5\n",
        "\n",
        "    return prediction.astype(np.uint8)"
      ],
      "metadata": {
        "id": "BYIP2PRlVjSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Connected Components Analysis**"
      ],
      "metadata": {
        "id": "FgiC_1sXVk4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_mining_clusters(prediction_mask):\n",
        "    \"\"\"\n",
        "    Analyzes a binary prediction mask to detect clusters of illegal mining activity.\n",
        "\n",
        "    Args:\n",
        "        prediction_mask (numpy.ndarray): A binary mask where 1 represents mining.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, where each dictionary contains information\n",
        "              about a detected mining cluster (e.g., area, bounding box, centroid).\n",
        "    \"\"\"\n",
        "    if prediction_mask is None:\n",
        "        print(\"Error: No prediction mask available for cluster analysis.\")\n",
        "        return []\n",
        "\n",
        "    labeled_mask = label(prediction_mask, connectivity=1)\n",
        "    regions = regionprops(labeled_mask)\n",
        "    mining_clusters = []\n",
        "    for region in regions:\n",
        "        if region.area > 10: # Example threshold\n",
        "            mining_clusters.append({\n",
        "                'area': region.area,\n",
        "                'bounding_box': region.bbox,\n",
        "                'centroid': region.centroid\n",
        "            })\n",
        "    return mining_clusters\n"
      ],
      "metadata": {
        "id": "shrErB6rVm4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Basic Risk Propagation (Conceptual)**"
      ],
      "metadata": {
        "id": "8_CsTwhYVoZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_risk_propagation(elevation_data, mining_locations, water_sources):\n",
        "    \"\"\"\n",
        "    A very basic conceptual implementation of risk propagation using Dijkstra's.\n",
        "    This requires actual elevation data and water source locations.\n",
        "\n",
        "    Args:\n",
        "        elevation_data (numpy.ndarray): A 2D array representing elevation.\n",
        "        mining_locations (list of tuples): Coordinates (row, col) of mining sites.\n",
        "        water_sources (list of tuples): Coordinates (row, col) of water sources.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary mapping mining locations to the nearest water source path (conceptual).\n",
        "    \"\"\"\n",
        "    if elevation_data is None or not mining_locations or not water_sources:\n",
        "        print(\"Error: Missing data for risk propagation analysis.\")\n",
        "        return {}\n",
        "\n",
        "    rows, cols = elevation_data.shape\n",
        "    graph = nx.grid_2d_graph(rows, cols)\n",
        "\n",
        "    # Define a very simple weight based on elevation (higher elevation = higher weight)\n",
        "    for u, v, data in graph.edges(data=True):\n",
        "        u_row, u_col = u\n",
        "        v_row, v_col = v\n",
        "        weight = (elevation_data[u_row, u_col] + elevation_data[v_row, v_col]) / 2 + 1\n",
        "        data['weight'] = weight\n",
        "\n",
        "    risk_paths = {}\n",
        "    for mining_loc in mining_locations:\n",
        "        shortest_path = None\n",
        "        min_distance = float('inf')\n",
        "        for water_loc in water_sources:\n",
        "            try:\n",
        "                path = nx.dijkstra_path(graph, source=mining_loc, target=water_loc, weight='weight')\n",
        "                distance = nx.dijkstra_path_length(graph, source=mining_loc, target=water_loc, weight='weight')\n",
        "                if distance < min_distance:\n",
        "                    min_distance = distance\n",
        "                    shortest_path = path\n",
        "            except nx.NetworkXNoPath:\n",
        "                pass\n",
        "\n",
        "        if shortest_path:\n",
        "            risk_paths[mining_loc] = f\"Path to nearest water source for {mining_loc}\" # Conceptual path\n",
        "\n",
        "    return risk_paths\n",
        "\n",
        "# Create dummy elevation data and water sources for demonstration\n",
        "if image_array is not None:\n",
        "    dummy_elevation_data = np.random.rand(image_array.shape[1], image_array.shape[2]) * 100\n",
        "    dummy_water_sources = [(50, 50), (150, 200)] # Example coordinates"
      ],
      "metadata": {
        "id": "zPmdmCh6Vq9N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}