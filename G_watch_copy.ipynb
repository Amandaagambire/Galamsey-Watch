{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amandaagambire/Galamsey-Watch/blob/main/G_watch_copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install Earth Engine**"
      ],
      "metadata": {
        "id": "Yg5BtzUQU6Qy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qikoNBhvUQDO"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install geemap\n",
        "!pip install folium\n",
        "!pip install rasterio\n",
        "!pip install segmentation-models-pytorch\n",
        "!pip install pyngrok\n",
        "!pip install flask\n",
        "!pip install earthengine-api --upgrade\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Authenticate & Initialize earth engine**"
      ],
      "metadata": {
        "id": "5wWtyLKPU9C9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import ee\n",
        "import geemap\n",
        "import folium\n",
        "import rasterio\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "import shutil\n",
        "from google.colab.output import eval_js\n",
        "from pyngrok import ngrok\n",
        "# from flask import Flask, request, jsonify, render_template\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Authenticae then initialise google Earth Engine\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project = 'ee-amandaagambire22')\n",
        "print(\"Earth Engine Initialized\")\n"
      ],
      "metadata": {
        "id": "Z1WkSYedU3kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA ACQUISITION: Fetching Sentinel -2 Images**"
      ],
      "metadata": {
        "id": "9LfiF6sVVCas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Region of Interest\n",
        "ghana = ee.FeatureCollection(\"FAO/GAUL/2015/level0\") \\\n",
        "          .filter(ee.Filter.eq('ADM0_NAME', 'Ghana'))\n",
        "# Define time range\n",
        "start_date = '2023-01-01'\n",
        "end_date = '2023-12-31'\n",
        "\n",
        "# Sentinel-2 ImageCollection\n",
        "sentinel = ee.ImageCollection('COPERNICUS/S2_SR') \\\n",
        "    .filterDate(start_date, end_date) \\\n",
        "    .filterBounds(ghana) \\\n",
        "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10)) \\\n",
        "    .median() \\\n",
        "    .clip(ghana)\n",
        "\n",
        "rgb_nir = sentinel.select(['B4', 'B3', 'B2', 'B8'])\n"
      ],
      "metadata": {
        "id": "R8ThROxJVC6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Vizulaize the Extracted images**\n"
      ],
      "metadata": {
        "id": "23YF_mloVEva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Map = geemap.Map(center = [5.2, -2.1], zoom=10)\n",
        "\n",
        "\n",
        "Map.addLayer(sentinel, {'min': 0, 'max': 3000}, \"Sentinel-2 RGB\")\n",
        "# Map.addLayer(landsat_rgb, {'min': 0, 'max': 3000}, \"Landsat-8\")\n",
        "\n",
        "#Lets see it\n",
        "Map"
      ],
      "metadata": {
        "id": "Pl8lIAHqVHE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **Export to Google Drive as GeoTIFF**"
      ],
      "metadata": {
        "id": "BRPeZzsK4oBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# task = ee.batch.Export.image.toDrive(\n",
        "#     image=rgb_nir,\n",
        "#     description='ghana_sentinel_image',\n",
        "#     folder='GEE_Exports',\n",
        "#     fileNamePrefix='ghana_rgbnir',\n",
        "#     region=ghana.geometry(),\n",
        "#     scale=10,\n",
        "#     maxPixels=1e13\n",
        "# )\n",
        "# task.start()\n"
      ],
      "metadata": {
        "id": "9g19v1cj4oia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load the GeoTIFF into Colab**"
      ],
      "metadata": {
        "id": "cKZ-hSh0VI1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import rasterio\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "base_path = '/content/drive/MyDrive/'\n",
        "\n",
        "# Show all folders/files inside your Drive root\n",
        "# for root, dirs, files in os.walk(base_path):\n",
        "#     print(f\"\\nIn folder: {root}\")\n",
        "#     for file in files:\n",
        "#         print(file)\n",
        "\n",
        "tif_path = '/content/drive/MyDrive/galamsey_detection/ghana_rgbnir.tif'\n",
        "if not os.path.exists(tif_path):\n",
        "    raise FileNotFoundError(f\"File not found at: {tif_path}\")\n",
        "\n",
        "with rasterio.open(tif_path) as src:\n",
        "    img = src.read()  # shape: (bands, height, width)\n",
        "    profile = src.profile\n"
      ],
      "metadata": {
        "id": "CTCooMdzVMZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Export images to Google Drive**"
      ],
      "metadata": {
        "id": "LLsceG94VODe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def export_image_to_drive(image, description='Sentinel-2_Mining_Area', folder = 'GEE_Exports'):\n",
        "  export_task = ee.batch.Export.image.toDrive(\n",
        "      image=image,\n",
        "      description=description,\n",
        "      scale=30,\n",
        "      region=region,\n",
        "      fileFormat='GeoTIFF',\n",
        "      folder= folder  # This is where the file will be saved in Drive\n",
        "  )\n",
        "  # Start the export task\n",
        "  export_task.start()\n",
        "  print(\"Export started! Check Google Drive â†’ GEE_Exports folder in 5-10 minutes.\")\n",
        "\n",
        "\n",
        "\n",
        "task_list = ee.batch.Task.list()\n",
        "for task in task_list:\n",
        "    print(task.status())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YThDboNUVQMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Moves a file from Google Drive to Colab**"
      ],
      "metadata": {
        "id": "0-C1LILFVSJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def move_file_from_drive_to_colab(source_path_on_drive, destination_path_on_colab):\n",
        "    \"\"\"Moves a file from Google Drive to Colab.\"\"\"\n",
        "    if IN_COLAB:\n",
        "        source_path = f\"/content/drive/My Drive/{source_path_on_drive}\"\n",
        "        try:\n",
        "            shutil.copy(source_path, destination_path_on_colab)\n",
        "            print(f\"File moved to Colab: {destination_path_on_colab}\")\n",
        "            return True\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: Source file not found at {source_path}\")\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            print(f\"Error moving file: {e}\")\n",
        "            return False\n",
        "    else:\n",
        "        print(\"Not running in Colab, skipping file move.\")\n",
        "        return False\n",
        "\n",
        "local_image_path = '/content/Sentinel2_Mining_Area.tif' # Assuming you have downloaded or moved the image\n"
      ],
      "metadata": {
        "id": "-EYbtxZsVUeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Download & Label for training**"
      ],
      "metadata": {
        "id": "hmXkus4uVXQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check if file exists in Google Colab\n",
        "print(os.listdir('/content/'))\n"
      ],
      "metadata": {
        "id": "Dxb0S_kGVZXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  with rasterio.open(local_image_path) as src:\n",
        "    image_array = src.read()\n",
        "    image_metadata = src.profile\n",
        "    red_band = image_array[0].astype(np.float32)\n",
        "    green_band = image_array[1].astype(np.float32)\n",
        "    blue_band = image_array[2].astype(np.float32)\n",
        "    # nir_band = image_array[3]\n",
        "except Exception as e:\n",
        "    print(f\"Error opening the image: {e}\")\n",
        "\n",
        "print(image_array.shape)\n",
        "  # Print metadta\n",
        "print(image_metadata)\n"
      ],
      "metadata": {
        "id": "m_mUwQxkVcyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **U-Net Model Definition**"
      ],
      "metadata": {
        "id": "q-ocX5puVfh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from logging import log\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNet, self).__init__()\n",
        "        self.inc = DoubleConv(in_channels, 64)\n",
        "        self.outc = nn.Conv2d(64, out_channels, kernel_size=1) # Simplified output\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        logits = self.outc(x1)\n",
        "        return logits\n",
        "\n",
        "# Load a pre-trained model (replace with the actual path to your trained model)\n",
        "n_channels = 3\n",
        "n_classes = 1\n",
        "model = UNet(n_channels, n_classes)\n",
        "try:\n",
        "    model.load_state_dict(torch.load('/content/drive/My Drive/galamsey_unet_simplified.pth', map_location=torch.device('cpu'))) # Load on CPU for simplicity\n",
        "    model.eval()\n",
        "    print(\"Pre-trained U-Net model loaded successfully!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Pre-trained U-Net model not found. Please train and save your model.\")\n",
        "    model = None\n",
        "\n",
        "# Define image transformation for prediction\n",
        "predict_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "wa8JUQGdVgE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prediction Function**"
      ],
      "metadata": {
        "id": "c6FPZXoqVi2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_mining_site(image_array, model, transform, device='cpu'):\n",
        "    \"\"\"\n",
        "    Performs prediction on an image using the U-Net model.\n",
        "\n",
        "    Args:\n",
        "        image_array (numpy.ndarray): The input image array (e.g., RGB).\n",
        "        model (torch.nn.Module): The trained U-Net model.\n",
        "        transform (torch.transforms): The image transformation pipeline.\n",
        "        device (str): 'cpu' or 'cuda'.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray or None: The binary prediction mask (1 for mining, 0 otherwise), or None if model is not loaded.\n",
        "    \"\"\"\n",
        "    if model is None or image_array is None:\n",
        "        print(\"Error: Model not loaded or image not available for prediction.\")\n",
        "        return None\n",
        "\n",
        "    # Assuming image_array is (bands, height, width), we need (height, width, bands) for PIL\n",
        "    rgb_image = np.transpose(image_array[:3, :, :], (1, 2, 0))\n",
        "    pil_image = Image.fromarray(rgb_image).convert('RGB')\n",
        "    input_tensor = transform(pil_image).unsqueeze(0).to(device) # Add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        prediction = torch.sigmoid(output).squeeze().cpu().numpy() > 0.5\n",
        "\n",
        "    return prediction.astype(np.uint8)"
      ],
      "metadata": {
        "id": "BYIP2PRlVjSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Connected Components Analysis**"
      ],
      "metadata": {
        "id": "FgiC_1sXVk4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_mining_clusters(prediction_mask):\n",
        "    \"\"\"\n",
        "    Analyzes a binary prediction mask to detect clusters of illegal mining activity.\n",
        "\n",
        "    Args:\n",
        "        prediction_mask (numpy.ndarray): A binary mask where 1 represents mining.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, where each dictionary contains information\n",
        "              about a detected mining cluster (e.g., area, bounding box, centroid).\n",
        "    \"\"\"\n",
        "    if prediction_mask is None:\n",
        "        print(\"Error: No prediction mask available for cluster analysis.\")\n",
        "        return []\n",
        "\n",
        "    labeled_mask = label(prediction_mask, connectivity=1)\n",
        "    regions = regionprops(labeled_mask)\n",
        "    mining_clusters = []\n",
        "    for region in regions:\n",
        "        if region.area > 10: # Example threshold\n",
        "            mining_clusters.append({\n",
        "                'area': region.area,\n",
        "                'bounding_box': region.bbox,\n",
        "                'centroid': region.centroid\n",
        "            })\n",
        "    return mining_clusters\n"
      ],
      "metadata": {
        "id": "shrErB6rVm4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Basic Risk Propagation (Conceptual)**"
      ],
      "metadata": {
        "id": "8_CsTwhYVoZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_risk_propagation(elevation_data, mining_locations, water_sources):\n",
        "    \"\"\"\n",
        "    A very basic conceptual implementation of risk propagation using Dijkstra's.\n",
        "    This requires actual elevation data and water source locations.\n",
        "\n",
        "    Args:\n",
        "        elevation_data (numpy.ndarray): A 2D array representing elevation.\n",
        "        mining_locations (list of tuples): Coordinates (row, col) of mining sites.\n",
        "        water_sources (list of tuples): Coordinates (row, col) of water sources.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary mapping mining locations to the nearest water source path (conceptual).\n",
        "    \"\"\"\n",
        "    if elevation_data is None or not mining_locations or not water_sources:\n",
        "        print(\"Error: Missing data for risk propagation analysis.\")\n",
        "        return {}\n",
        "\n",
        "    rows, cols = elevation_data.shape\n",
        "    graph = nx.grid_2d_graph(rows, cols)\n",
        "\n",
        "    # Define a very simple weight based on elevation (higher elevation = higher weight)\n",
        "    for u, v, data in graph.edges(data=True):\n",
        "        u_row, u_col = u\n",
        "        v_row, v_col = v\n",
        "        weight = (elevation_data[u_row, u_col] + elevation_data[v_row, v_col]) / 2 + 1\n",
        "        data['weight'] = weight\n",
        "\n",
        "    risk_paths = {}\n",
        "    for mining_loc in mining_locations:\n",
        "        shortest_path = None\n",
        "        min_distance = float('inf')\n",
        "        for water_loc in water_sources:\n",
        "            try:\n",
        "                path = nx.dijkstra_path(graph, source=mining_loc, target=water_loc, weight='weight')\n",
        "                distance = nx.dijkstra_path_length(graph, source=mining_loc, target=water_loc, weight='weight')\n",
        "                if distance < min_distance:\n",
        "                    min_distance = distance\n",
        "                    shortest_path = path\n",
        "            except nx.NetworkXNoPath:\n",
        "                pass\n",
        "\n",
        "        if shortest_path:\n",
        "            risk_paths[mining_loc] = f\"Path to nearest water source for {mining_loc}\" # Conceptual path\n",
        "\n",
        "    return risk_paths\n",
        "\n",
        "# Create dummy elevation data and water sources for demonstration\n",
        "if image_array is not None:\n",
        "    dummy_elevation_data = np.random.rand(image_array.shape[1], image_array.shape[2]) * 100\n",
        "    dummy_water_sources = [(50, 50), (150, 200)] # Example coordinates"
      ],
      "metadata": {
        "id": "zPmdmCh6Vq9N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}